import React, { useState, useEffect } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import '../styles/VoiceAssistant.css';

const VoiceAssistant = ({ onUpdateMedias }) => {
  const [isPanelOpen, setIsPanelOpen] = useState(false);
  const [conversation, setConversation] = useState([]);
  const [isLoading, setIsLoading] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [mediaData, setMediaData] = useState([]);
  
  const {
    transcript,
    listening,
    resetTranscript,
    browserSupportsSpeechRecognition
  } = useSpeechRecognition();

  // è‡ªåŠ¨è§¦å‘æœç´¢
  useEffect(() => {
    if (!listening && transcript.trim()) {
      handleAutoSearch();
    }
  }, [listening]);

  const handleAutoSearch = async () => {
    const userMessage = {
      type: 'user',
      content: transcript,
      timestamp: new Date().toLocaleTimeString()
    };
    
    setConversation(prev => [...prev, userMessage]);
    setIsLoading(true);
    
    try {
      // APIè°ƒç”¨ - æŒ‰ç…§æ‚¨çš„è¦æ±‚é…ç½®headerså’Œbody
      const searchUrl = `http://localhost:8000/agent/voice_media_search?message=${encodeURIComponent(transcript)}`;
      const response = await fetch(searchUrl, {
        method: 'GET',
        mode: 'cors',  // æ˜ç¡®å¯ç”¨CORSæ¨¡å¼
        headers: {
          'Content-Type': 'application/json', // æ˜ç¡®å£°æ˜æœŸæœ›JSONå“åº”
        },
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('ğŸ”´ HTTPé”™è¯¯:', {
          status: response.status,
          statusText: response.statusText,
          headers: [...response.headers.entries()], // æ˜¾ç¤ºå“åº”å¤´
          body: errorText
        });
        throw new Error(`HTTP ${response.status}: ${errorText}`);
      }
      
      let data;
      try {
        data = await response.json();
        console.log('ğŸŸ¢ è¯­éŸ³åŠ©æ‰‹è§£ææˆåŠŸ:', data); // è°ƒè¯•3ï¼šæ‰“å°è§£æåçš„æ•°æ®
      } catch (jsonError) {
        const textBody = await response.text();
        console.error('ğŸ”´ è¯­éŸ³åŠ©æ‰‹è§£æå¤±è´¥:', {
          error: jsonError,
          rawText: textBody,
          headers: [...response.headers.entries()]
        });
        throw new Error(`å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSON: ${textBody.substring(0, 100)}...`);
      }

      const botMessage = {
        content: data.chat,
        timestamp: new Date().toLocaleTimeString()
      };
      
      setConversation(prev => [...prev, botMessage]);
      speak(botMessage.content);

      if (data.medias_info) {
        setMediaData(data.medias_info);
      }
    } catch (error) {
      console.error('âŒ å®Œæ•´é”™è¯¯é“¾:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      
      setConversation(prev => [...prev, {
        type: 'error',
        content: `è¯·æ±‚å¤±è´¥: ${error.message.replace('Failed to fetch', 'ç½‘ç»œè¿æ¥å¤±è´¥')}`,
        timestamp: new Date().toLocaleTimeString()
      }]);
    } finally {
      setIsLoading(false);
      resetTranscript();
    }
  };

  // æ–°å¢ï¼šå°†è§†é¢‘æ•°æ®æ¨é€åˆ°çˆ¶ç»„ä»¶
  const handleAddToMedias = (mediaData) => {
      console.log(mediaData)
      onUpdateMedias(mediaData);
      mediaData = []
  };

  const speak = (text) => {
    if (!window.speechSynthesis) return;
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'zh-CN';
    utterance.rate = 1.2; // é€‚å½“è¯­é€Ÿ
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = (e) => {
      console.error('è¯­éŸ³åˆæˆé”™è¯¯:', e);
      setIsSpeaking(false);
    };
    window.speechSynthesis.speak(utterance);
  };

  const toggleListening = () => {
    if (listening) {
      SpeechRecognition.stopListening();
    } else {
      resetTranscript();
      SpeechRecognition.startListening({ 
        language: 'zh-CN',
        continuous: false // è‡ªåŠ¨ç»“æŸ
      });
    }
  };

  if (!browserSupportsSpeechRecognition) {
    return (
      <button className="voice-btn" disabled>
        ğŸ¤ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«
      </button>
    );
  }

  return (
    <>
      {/* è§¦å‘æŒ‰é’® - ä¿ç•™åŸæœ‰ä½ç½®å’Œæ ·å¼ */}
      <button 
        className={`voice-btn ${isPanelOpen ? 'active' : ''}`}
        onClick={() => setIsPanelOpen(!isPanelOpen)}
      >
        {isPanelOpen ? 'âœ• å…³é—­' : 'ğŸ¤ è¯­éŸ³åŠ©æ‰‹'}
      </button>

      {/* å³ä¾§æ‚¬æµ®é¢æ¿ - å®Œæ•´ä¿ç•™åŸæœ‰è®¾è®¡ */}
      {isPanelOpen && (
        <div className="voice-panel-overlay" onClick={() => setIsPanelOpen(false)}>
          <div className="voice-panel" onClick={(e) => e.stopPropagation()}>
            <div className="panel-header">
              <h3>è¯­éŸ³å¯¹è¯åŠ©æ‰‹</h3>
              <button 
                className="close-btn"
                onClick={() => setIsPanelOpen(false)}
              >
                âœ•
              </button>
            </div>
            
            {/* å¯¹è¯å†å²åŒºåŸŸ */}
            <div className="conversation-history">
              {conversation.map((msg, i) => (
                <div key={i} className={`message-bubble ${msg.type}`}>
                  <div className="message-content">
                    {msg.content}
                    {msg.type === 'bot' && (
                      <button 
                        onClick={() => speak(msg.content)} 
                        className="speak-btn"
                        disabled={isSpeaking}
                      >
                        {isSpeaking ? 'ğŸ›‘ åœæ­¢' : 'ğŸ”Š æœ—è¯»'}
                      </button>
                    )}
                  </div>
                  <div className="message-time">{msg.timestamp}</div>
                </div>
              ))}
              
              {isLoading && (
                <div className="message-bubble bot">
                  <div className="message-content">æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...</div>
                </div>
              )}
            </div>

            {/*mediaData.length > 0 && (
              <button 
                onClick={() => handleAddToMedias(mediaData)}
                className="add-video-btn"
              >
                â• æ·»åŠ åˆ°æ¨èè§†é¢‘
              </button>
            )*/}
            
            {/* è¯­éŸ³æ§åˆ¶åŒºåŸŸ */}
            <div className="voice-controls">
              <button
                onClick={toggleListening}
                className={`mic-button ${listening ? 'active' : ''}`}
                disabled={isLoading}
              >
                {listening ? (
                  <>
                    <span className="pulse-animation"></span>
                    ğŸ¤ è†å¬ä¸­...
                  </>
                ) : 'ğŸ¤ å¼€å§‹è¯´è¯'}
              </button>
              <div className="status-text">
                {transcript || (listening ? "è¯·è¯´å‡ºæ‚¨çš„éœ€æ±‚..." : "ç‚¹å‡»éº¦å…‹é£å¼€å§‹å¯¹è¯")}
              </div>
            </div>
          </div>
        </div>
      )}
    </>
  );
};

export default VoiceAssistant;